## AUTOMATIC IMAGE CAPTIONING USING CNN-LSTM DEEP NEURAL NETWORKS AND FLASK [![](https://img.shields.io/github/license/sourcerer-io/hall-of-fame.svg?colorB=ff0000)](https://github.com/yaswanthpalaghat/Automatic-Image-Captioning-using-CNN-LSTM-deep-neural-networks-and-flask/blob/master/LICENSE)  

### Description

Image caption generation has emerged as a challenging and important research area following ad-vances in statistical language modelling and image recognition. The generation of captions from images has various practical benefits, ranging from aiding the visually impaired, to enabling the automatic and cost-saving labelling of the millions of images uploaded to the Internet every day. The field also brings together state-of-the-art models in Natural Language Processing and Computer Vision, two of the major fields in Artificial Intelligence.
In this model, we has used CNN and LSTM to generate captions for the images and deployed our model using Flask.


### Deployment Procedure

## 1.Download and Install Python 3x and make sure to set the path(it is automated most of the times).
## 2.Download Anaconda IDE and Visual Studio Code.
## 3.Download Flickr8k dataset through the below link:

              https://illinois.edu/fb/sec/1713398

Place the dataset files in image-captoin/train_val_data
              

## 4.Download the following libraries required by the project through the PIP using the following format.
## PIP INSTALL << LIBRARY NAME >>
•	tensorflow
•	keras
•	numpy
•	pandas
•	opencv-python
•	flask
•	flask-caption
•	scikit-learn
•	nltk
•	pytorch
•	theano
•	corpus
•	textblob
•	scipy
•	matplotlib


## 5.Download the code from the following github repository.
          https://github.com/yaswanthpalaghat/Automatic-Image-Captioning-using-CNN-LSTM-deep-neural-networks-and-flask
## 6.Run app.py and cap.py in the terminal.
## 7.Open browser and type Localhost:3000.




